{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sc\n",
    "import sklearn\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.metrics import r2_score\n",
    "import statsmodels.api as sm\n",
    "import sys\n",
    "### Gensim is outside the anaconda distribution ###\n",
    "### uncomment to install Gensim ###\n",
    "#!{sys.executable} -m pip install gensim\n",
    "import gensim\n",
    "import gensim.downloader as model_api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pretrained word embeddings\n",
    "# This will download 60mb of data the first time it's loaded\n",
    "word_vectors = model_api.load(\"glove-wiki-gigaword-50\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is some good information decomposing word embeddings on [Jay Alammar's blog](http://jalammar.github.io/illustrated-word2vec/).\n",
    "\n",
    "Word embedding dimensions capture high level concepts, which let algebra \"work\" in cosine distance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[('queen', 0.9288907647132874),\n ('throne', 0.882325291633606),\n ('elizabeth', 0.878950297832489),\n ('princess', 0.876754879951477),\n ('daughter', 0.8705160617828369),\n ('prince', 0.8702554702758789),\n ('kingdom', 0.8607221841812134),\n ('eldest', 0.8595449328422546),\n ('monarch', 0.8584719896316528),\n ('widow', 0.8549266457557678)]"
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "# Get the most similar word to an expression\n",
    "word_vectors.most_similar_cosmul(positive=['king', 'woman'], negative=['man'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentence embeddings\n",
    "\n",
    "The simplest and most effective way to represent a sentence is to sum or average the sentence's words. There are [some better methods](https://openreview.net/forum?id=SyK00v5xx) using weights, or using deep learning language models, but sentence embeddings are often just as good while being simpler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "      insult             date  \\\n0          1  20120618192155Z   \n1          0  20120528192215Z   \n2          0              NaN   \n3          0              NaN   \n4          0  20120619094753Z   \n...      ...              ...   \n3942       1  20120502172717Z   \n3943       0  20120528164814Z   \n3944       0  20120620142813Z   \n3945       0  20120528205648Z   \n3946       0  20120515200734Z   \n\n                                                comment  \n0                                  \"You fuck your dad.\"  \n1     \"i really don't understand your point.\\xa0 It ...  \n2     \"A\\\\xc2\\\\xa0majority of Canadians can and has ...  \n3     \"listen if you dont wanna get married to a man...  \n4     \"C\\xe1c b\\u1ea1n xu\\u1ed1ng \\u0111\\u01b0\\u1edd...  \n...                                                 ...  \n3942  \"you are both morons and that is never happening\"  \n3943  \"Many toolbars include spell check, like Yahoo...  \n3944  \"@LambeauOrWrigley\\xa0\\xa0@K.Moss\\xa0\\nSioux F...  \n3945  \"How about Felix? He is sure turning into one ...  \n3946  \"You're all upset, defending this hipster band...  \n\n[3947 rows x 3 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>insult</th>\n      <th>date</th>\n      <th>comment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>20120618192155Z</td>\n      <td>\"You fuck your dad.\"</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>20120528192215Z</td>\n      <td>\"i really don't understand your point.\\xa0 It ...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>NaN</td>\n      <td>\"A\\\\xc2\\\\xa0majority of Canadians can and has ...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>NaN</td>\n      <td>\"listen if you dont wanna get married to a man...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>20120619094753Z</td>\n      <td>\"C\\xe1c b\\u1ea1n xu\\u1ed1ng \\u0111\\u01b0\\u1edd...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>3942</th>\n      <td>1</td>\n      <td>20120502172717Z</td>\n      <td>\"you are both morons and that is never happening\"</td>\n    </tr>\n    <tr>\n      <th>3943</th>\n      <td>0</td>\n      <td>20120528164814Z</td>\n      <td>\"Many toolbars include spell check, like Yahoo...</td>\n    </tr>\n    <tr>\n      <th>3944</th>\n      <td>0</td>\n      <td>20120620142813Z</td>\n      <td>\"@LambeauOrWrigley\\xa0\\xa0@K.Moss\\xa0\\nSioux F...</td>\n    </tr>\n    <tr>\n      <th>3945</th>\n      <td>0</td>\n      <td>20120528205648Z</td>\n      <td>\"How about Felix? He is sure turning into one ...</td>\n    </tr>\n    <tr>\n      <th>3946</th>\n      <td>0</td>\n      <td>20120515200734Z</td>\n      <td>\"You're all upset, defending this hipster band...</td>\n    </tr>\n  </tbody>\n</table>\n<p>3947 rows × 3 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "source": [
    "df = pd.read_csv(\"data/troll.csv\")\n",
    "df.columns = [x.lower() for x in df.columns]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = df.comment.str.split()\n",
    "words = pd.DataFrame(words.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's clean the words up:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "                   0         1            2       3           4        5     \\\n0                   you      fuck         your     dad        None     None   \n1                     i    really          don       t  understand     your   \n2                     a       xc2  xa0majority      of   canadians      can   \n3                listen        if          you    dont       wanna      get   \n4                     c      xe1c            b  u1ea1n          xu  u1ed1ng   \n...                 ...       ...          ...     ...         ...      ...   \n3942                you       are         both  morons         and     that   \n3943               many  toolbars      include   spell       check     like   \n3944  @lambeauorwrigley       xa0        xa0@k    moss         xa0   nsioux   \n3945                how     about        felix      he          is     sure   \n3946                you        re          all   upset   defending     this   \n\n         6      7          8      9     ...  2481  2482  2483  2484  2485  \\\n0        None   None       None   None  ...  None  None  None  None  None   \n1       point    xa0         it  seems  ...  None  None  None  None  None   \n2         and    has       been  wrong  ...  None  None  None  None  None   \n3     married     to          a    man  ...  None  None  None  None  None   \n4       u0111  u01b0    u1eddng     bi  ...  None  None  None  None  None   \n...       ...    ...        ...    ...  ...   ...   ...   ...   ...   ...   \n3942       is  never  happening   None  ...  None  None  None  None  None   \n3943    yahoo    for    example    you  ...  None  None  None  None  None   \n3944    falls      s          d      i  ...  None  None  None  None  None   \n3945  turning   into        one   hell  ...  None  None  None  None  None   \n3946  hipster   band        and     we  ...  None  None  None  None  None   \n\n      2486  2487  2488  2489  2490  \n0     None  None  None  None  None  \n1     None  None  None  None  None  \n2     None  None  None  None  None  \n3     None  None  None  None  None  \n4     None  None  None  None  None  \n...    ...   ...   ...   ...   ...  \n3942  None  None  None  None  None  \n3943  None  None  None  None  None  \n3944  None  None  None  None  None  \n3945  None  None  None  None  None  \n3946  None  None  None  None  None  \n\n[3947 rows x 2491 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>...</th>\n      <th>2481</th>\n      <th>2482</th>\n      <th>2483</th>\n      <th>2484</th>\n      <th>2485</th>\n      <th>2486</th>\n      <th>2487</th>\n      <th>2488</th>\n      <th>2489</th>\n      <th>2490</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>you</td>\n      <td>fuck</td>\n      <td>your</td>\n      <td>dad</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>...</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>i</td>\n      <td>really</td>\n      <td>don</td>\n      <td>t</td>\n      <td>understand</td>\n      <td>your</td>\n      <td>point</td>\n      <td>xa0</td>\n      <td>it</td>\n      <td>seems</td>\n      <td>...</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>a</td>\n      <td>xc2</td>\n      <td>xa0majority</td>\n      <td>of</td>\n      <td>canadians</td>\n      <td>can</td>\n      <td>and</td>\n      <td>has</td>\n      <td>been</td>\n      <td>wrong</td>\n      <td>...</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>listen</td>\n      <td>if</td>\n      <td>you</td>\n      <td>dont</td>\n      <td>wanna</td>\n      <td>get</td>\n      <td>married</td>\n      <td>to</td>\n      <td>a</td>\n      <td>man</td>\n      <td>...</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>c</td>\n      <td>xe1c</td>\n      <td>b</td>\n      <td>u1ea1n</td>\n      <td>xu</td>\n      <td>u1ed1ng</td>\n      <td>u0111</td>\n      <td>u01b0</td>\n      <td>u1eddng</td>\n      <td>bi</td>\n      <td>...</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>3942</th>\n      <td>you</td>\n      <td>are</td>\n      <td>both</td>\n      <td>morons</td>\n      <td>and</td>\n      <td>that</td>\n      <td>is</td>\n      <td>never</td>\n      <td>happening</td>\n      <td>None</td>\n      <td>...</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>3943</th>\n      <td>many</td>\n      <td>toolbars</td>\n      <td>include</td>\n      <td>spell</td>\n      <td>check</td>\n      <td>like</td>\n      <td>yahoo</td>\n      <td>for</td>\n      <td>example</td>\n      <td>you</td>\n      <td>...</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>3944</th>\n      <td>@lambeauorwrigley</td>\n      <td>xa0</td>\n      <td>xa0@k</td>\n      <td>moss</td>\n      <td>xa0</td>\n      <td>nsioux</td>\n      <td>falls</td>\n      <td>s</td>\n      <td>d</td>\n      <td>i</td>\n      <td>...</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>3945</th>\n      <td>how</td>\n      <td>about</td>\n      <td>felix</td>\n      <td>he</td>\n      <td>is</td>\n      <td>sure</td>\n      <td>turning</td>\n      <td>into</td>\n      <td>one</td>\n      <td>hell</td>\n      <td>...</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>3946</th>\n      <td>you</td>\n      <td>re</td>\n      <td>all</td>\n      <td>upset</td>\n      <td>defending</td>\n      <td>this</td>\n      <td>hipster</td>\n      <td>band</td>\n      <td>and</td>\n      <td>we</td>\n      <td>...</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n    </tr>\n  </tbody>\n</table>\n<p>3947 rows × 2491 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "replaceDict = dict({\n",
    "'{':\" \", '}':\" \", ',':\"\", '.':\" \", '!':\" \", '\\\\':\" \", '/':\" \", '$':\" \", '%':\" \",\n",
    "'^':\" \", '?':\" \", '\\'':\" \", '\"':\" \", '(':\" \", ')':\" \", '*':\" \", '+':\" \", '-':\" \",\n",
    "'=':\" \", ':':\" \", ';':\" \", ']':\" \", '[':\" \", '`':\" \", '~':\" \",\n",
    "})\n",
    "\n",
    "rep = dict((re.escape(k), v) for k, v in replaceDict.items())\n",
    "pattern = re.compile(\"|\".join(rep.keys()))\n",
    "def replacer(text):\n",
    "    return rep[re.escape(text.group(0))]\n",
    "\n",
    "words = df.comment.str.replace(pattern, replacer).str.lower().str.split()\n",
    "words = pd.DataFrame(words.tolist())\n",
    "words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentence embeddings quickly\n",
    "\n",
    "This is a short way to generate sentence embeddings from a column.\n",
    "\n",
    "It's not very efficient and can be optimized a lot, though"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "            0         1         2         3         4         5         6   \\\n0    -1.552125  0.848600  0.910060 -2.855960  3.130450 -1.382110 -0.664681   \n1    -0.809713  0.444310 -0.170361  0.519650  1.639630 -1.408988 -1.431460   \n2     0.925580  1.036030 -0.939170  0.281300  1.557990  1.474480 -0.349470   \n3     0.984628  0.410783  1.452170 -2.068327  1.465770 -2.765390 -0.620257   \n4    -0.789980  0.814320  0.615490  1.806600  1.655930  0.836760  1.297190   \n...        ...       ...       ...       ...       ...       ...       ...   \n3942  1.028558 -0.162314  1.025981 -1.619540  1.495300 -0.094800 -0.645170   \n3943  2.516875  0.420063 -1.881124 -0.264210 -1.111890  0.797190 -2.294540   \n3944 -0.645630  0.635280 -0.245820  0.158380  0.026548  0.614830 -1.722900   \n3945  2.227540  0.215140  0.155670 -1.126360  2.026350 -0.482939 -1.700610   \n3946  0.026168 -0.199190  0.877717 -0.018792  1.236240  0.039660 -1.435920   \n\n            7         8         9   ...        40        41        42  \\\n0     0.110994  0.332940  1.048678  ...  1.091860 -0.290650 -2.290890   \n1    -1.140770 -2.752543  0.100198  ...  0.047036  1.614048 -1.388177   \n2    -0.786490  0.271930 -0.043840  ... -0.209140  0.654560 -0.567197   \n3     1.445397 -1.201449  1.350200  ...  0.443955  0.315920 -0.401230   \n4    -2.180100  0.429000  1.341210  ...  1.526580  0.654890  0.291433   \n...        ...       ...       ...  ...       ...       ...       ...   \n3942 -1.350557 -2.186080  0.532649  ... -0.865516 -0.051755  0.820879   \n3943 -1.572460 -0.762668  0.912920  ... -0.409087  1.071230  0.517720   \n3944 -0.663420  0.264600 -0.409590  ...  0.474210  0.379990 -0.610310   \n3945  0.818070 -2.132360  0.212580  ... -1.046870  1.698601  0.623800   \n3946  1.254767 -1.761340  0.243827  ... -0.834910 -0.261226  0.258610   \n\n            43        44        45        46        47        48        49  \n0     2.069010  1.017153 -0.045770  1.597997 -2.269570  0.493802  2.511670  \n1     0.799910  0.799906 -0.294300 -0.281051 -2.259776 -0.534389  4.159340  \n2    -0.038036 -0.429195 -0.031350 -0.096000 -0.269402  0.316212 -0.624150  \n3     2.645420 -0.151940  0.170872  0.417923  0.263880 -0.998752  3.392430  \n4     0.167440 -0.857240  2.045300  0.228305 -1.293180  1.370850  1.473740  \n...        ...       ...       ...       ...       ...       ...       ...  \n3942  3.084972  0.362180  0.253310 -0.971350 -0.306874 -0.933339  0.610880  \n3943  2.127889  0.270960  1.529950  0.236790  0.207239  0.298230 -1.649290  \n3944  0.195210 -0.187130 -0.193770  0.361500 -0.368440 -0.372750 -0.179140  \n3945  0.890860  0.305628 -0.110268 -0.707204 -0.980380 -1.087599  0.942129  \n3946  0.954602  0.289320  1.899120 -1.014840 -0.438764  0.171611  1.208040  \n\n[3947 rows x 50 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>...</th>\n      <th>40</th>\n      <th>41</th>\n      <th>42</th>\n      <th>43</th>\n      <th>44</th>\n      <th>45</th>\n      <th>46</th>\n      <th>47</th>\n      <th>48</th>\n      <th>49</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>-1.552125</td>\n      <td>0.848600</td>\n      <td>0.910060</td>\n      <td>-2.855960</td>\n      <td>3.130450</td>\n      <td>-1.382110</td>\n      <td>-0.664681</td>\n      <td>0.110994</td>\n      <td>0.332940</td>\n      <td>1.048678</td>\n      <td>...</td>\n      <td>1.091860</td>\n      <td>-0.290650</td>\n      <td>-2.290890</td>\n      <td>2.069010</td>\n      <td>1.017153</td>\n      <td>-0.045770</td>\n      <td>1.597997</td>\n      <td>-2.269570</td>\n      <td>0.493802</td>\n      <td>2.511670</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>-0.809713</td>\n      <td>0.444310</td>\n      <td>-0.170361</td>\n      <td>0.519650</td>\n      <td>1.639630</td>\n      <td>-1.408988</td>\n      <td>-1.431460</td>\n      <td>-1.140770</td>\n      <td>-2.752543</td>\n      <td>0.100198</td>\n      <td>...</td>\n      <td>0.047036</td>\n      <td>1.614048</td>\n      <td>-1.388177</td>\n      <td>0.799910</td>\n      <td>0.799906</td>\n      <td>-0.294300</td>\n      <td>-0.281051</td>\n      <td>-2.259776</td>\n      <td>-0.534389</td>\n      <td>4.159340</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.925580</td>\n      <td>1.036030</td>\n      <td>-0.939170</td>\n      <td>0.281300</td>\n      <td>1.557990</td>\n      <td>1.474480</td>\n      <td>-0.349470</td>\n      <td>-0.786490</td>\n      <td>0.271930</td>\n      <td>-0.043840</td>\n      <td>...</td>\n      <td>-0.209140</td>\n      <td>0.654560</td>\n      <td>-0.567197</td>\n      <td>-0.038036</td>\n      <td>-0.429195</td>\n      <td>-0.031350</td>\n      <td>-0.096000</td>\n      <td>-0.269402</td>\n      <td>0.316212</td>\n      <td>-0.624150</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.984628</td>\n      <td>0.410783</td>\n      <td>1.452170</td>\n      <td>-2.068327</td>\n      <td>1.465770</td>\n      <td>-2.765390</td>\n      <td>-0.620257</td>\n      <td>1.445397</td>\n      <td>-1.201449</td>\n      <td>1.350200</td>\n      <td>...</td>\n      <td>0.443955</td>\n      <td>0.315920</td>\n      <td>-0.401230</td>\n      <td>2.645420</td>\n      <td>-0.151940</td>\n      <td>0.170872</td>\n      <td>0.417923</td>\n      <td>0.263880</td>\n      <td>-0.998752</td>\n      <td>3.392430</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>-0.789980</td>\n      <td>0.814320</td>\n      <td>0.615490</td>\n      <td>1.806600</td>\n      <td>1.655930</td>\n      <td>0.836760</td>\n      <td>1.297190</td>\n      <td>-2.180100</td>\n      <td>0.429000</td>\n      <td>1.341210</td>\n      <td>...</td>\n      <td>1.526580</td>\n      <td>0.654890</td>\n      <td>0.291433</td>\n      <td>0.167440</td>\n      <td>-0.857240</td>\n      <td>2.045300</td>\n      <td>0.228305</td>\n      <td>-1.293180</td>\n      <td>1.370850</td>\n      <td>1.473740</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>3942</th>\n      <td>1.028558</td>\n      <td>-0.162314</td>\n      <td>1.025981</td>\n      <td>-1.619540</td>\n      <td>1.495300</td>\n      <td>-0.094800</td>\n      <td>-0.645170</td>\n      <td>-1.350557</td>\n      <td>-2.186080</td>\n      <td>0.532649</td>\n      <td>...</td>\n      <td>-0.865516</td>\n      <td>-0.051755</td>\n      <td>0.820879</td>\n      <td>3.084972</td>\n      <td>0.362180</td>\n      <td>0.253310</td>\n      <td>-0.971350</td>\n      <td>-0.306874</td>\n      <td>-0.933339</td>\n      <td>0.610880</td>\n    </tr>\n    <tr>\n      <th>3943</th>\n      <td>2.516875</td>\n      <td>0.420063</td>\n      <td>-1.881124</td>\n      <td>-0.264210</td>\n      <td>-1.111890</td>\n      <td>0.797190</td>\n      <td>-2.294540</td>\n      <td>-1.572460</td>\n      <td>-0.762668</td>\n      <td>0.912920</td>\n      <td>...</td>\n      <td>-0.409087</td>\n      <td>1.071230</td>\n      <td>0.517720</td>\n      <td>2.127889</td>\n      <td>0.270960</td>\n      <td>1.529950</td>\n      <td>0.236790</td>\n      <td>0.207239</td>\n      <td>0.298230</td>\n      <td>-1.649290</td>\n    </tr>\n    <tr>\n      <th>3944</th>\n      <td>-0.645630</td>\n      <td>0.635280</td>\n      <td>-0.245820</td>\n      <td>0.158380</td>\n      <td>0.026548</td>\n      <td>0.614830</td>\n      <td>-1.722900</td>\n      <td>-0.663420</td>\n      <td>0.264600</td>\n      <td>-0.409590</td>\n      <td>...</td>\n      <td>0.474210</td>\n      <td>0.379990</td>\n      <td>-0.610310</td>\n      <td>0.195210</td>\n      <td>-0.187130</td>\n      <td>-0.193770</td>\n      <td>0.361500</td>\n      <td>-0.368440</td>\n      <td>-0.372750</td>\n      <td>-0.179140</td>\n    </tr>\n    <tr>\n      <th>3945</th>\n      <td>2.227540</td>\n      <td>0.215140</td>\n      <td>0.155670</td>\n      <td>-1.126360</td>\n      <td>2.026350</td>\n      <td>-0.482939</td>\n      <td>-1.700610</td>\n      <td>0.818070</td>\n      <td>-2.132360</td>\n      <td>0.212580</td>\n      <td>...</td>\n      <td>-1.046870</td>\n      <td>1.698601</td>\n      <td>0.623800</td>\n      <td>0.890860</td>\n      <td>0.305628</td>\n      <td>-0.110268</td>\n      <td>-0.707204</td>\n      <td>-0.980380</td>\n      <td>-1.087599</td>\n      <td>0.942129</td>\n    </tr>\n    <tr>\n      <th>3946</th>\n      <td>0.026168</td>\n      <td>-0.199190</td>\n      <td>0.877717</td>\n      <td>-0.018792</td>\n      <td>1.236240</td>\n      <td>0.039660</td>\n      <td>-1.435920</td>\n      <td>1.254767</td>\n      <td>-1.761340</td>\n      <td>0.243827</td>\n      <td>...</td>\n      <td>-0.834910</td>\n      <td>-0.261226</td>\n      <td>0.258610</td>\n      <td>0.954602</td>\n      <td>0.289320</td>\n      <td>1.899120</td>\n      <td>-1.014840</td>\n      <td>-0.438764</td>\n      <td>0.171611</td>\n      <td>1.208040</td>\n    </tr>\n  </tbody>\n</table>\n<p>3947 rows × 50 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "source": [
    "def soft_get(w):\n",
    "    try:\n",
    "        return word_vectors[w]\n",
    "    except KeyError:\n",
    "        return np.zeros(word_vectors.vector_size)\n",
    "\n",
    "def map_vectors(row):\n",
    "    try:\n",
    "        return np.sum(\n",
    "            row.loc[words.iloc[0].notna()].apply(soft_get)\n",
    "        )\n",
    "    except:\n",
    "        return np.zeros(word_vectors.vector_size)\n",
    "\n",
    "emb = pd.DataFrame(words.apply(map_vectors, axis=1).tolist())\n",
    "emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "SGDRegressor()"
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "source": [
    "sgdr = SGDRegressor()\n",
    "sgdr.fit(emb, df.insult)\n",
    "sgdr.score(emb, df.insult)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "35% R^2 versus 25% when we were using TF-IDF! A huge win.\n",
    "\n",
    "We could also augment our embeddings with TF-IDF weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}